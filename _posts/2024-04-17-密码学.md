### 离散概率

首先有一个世界 $U$ 包含有限个元素。 $U$ 中每一个元素都有一个概率，所有元素的概率加起来等于一。
而给这些元素不同的概率就形成了不同的概率分布。比较常见的分布是均匀分布，就是所有元素的概率都相等。

#### 事件

这个世界会发生一些事件 $A$ 每个事件都是由一些元素组成的，所以事件是 $U$ 的子集。一个事件发生的概率就是这个子集 $A$ 中所有元素概率之和。

假设有两个事件 $A$ 和 $B$ 如果满足 $p(A\cap B) = p(A)p(B)$ 我们就说这两个事件是独立的，发生 $A$ 不会影响发生 $B$ 的概率。我们也可以理解为：在世界 $U$ 中发生 $B$ 的概率和在 $A$ 中发生 $B$ 的概率相等 $$p(B) = \frac{p(A \cap B)}{p(A)}$$ 例如`掷色子结果为偶数`这个事件与`结果小于3`这个事件就是独立的，因为无论有没有`结果小于3`这个事件，`结果为偶数`的概率都是 $\frac12$ 但是`结果为偶数`与`结果小于4`就不独立了。因为当`结果小于4`时`结果为偶数`的概率为 $\frac13$

#### 随机变量

随机变量 $r$ 是沟通两个世界 $U$ $V$ 的桥梁，他是一个 $U$ 到 $V$ 的函数， $r$ 和 $U$ 共同定义了 $V$ 的一个分布。这个定义有点奇怪，因为涉及到具体的随机元素如何产生。
但我们可以把他理解为 $r$ 是一个取值范围为 $V$ 的随机变量。而 $r$ 定义了 $V$ 的一个分布。（说人话就是定义了 $V$ 上每个元素可能出现的概率）

一个均匀随机变量 $r$ 输出 $V$ 中任何一个元素的概率都是相等的。相当于概率分布是均匀分布。
$$r\xleftarrow{\text{R}}V$$

我们有了随机变量之后就可以在一些算法中加入随机性，让他成为一个随机算法。相比于确定算法 $y=F(m)$ 随机算法引入了一个均匀随机变量 $y'=F(m, r)$
前者有一个确定的结果 $y$ 而后者返回的是一个随机变量 $y'$ 当 $F(m, r)$ 是可逆函数的时候， $y'$ 也是一个均匀随机变量，他的取值范围就是 $F(m, r)$ 所有可能的结果。（注意这里 $m$ 是固定的而 $r$ 是随机变量）

如果有两个 $V$ 上的随机变量， $X, Y$ 当满足 $\forall{a, b} \in V : p(X=a,Y=b) = P(X=a)P(Y=b)$ 这两个随机变量就是独立的。我们无法从一个随机变量推测出任何另一个随机变量的信息。这个独立和事件的独立不太一样，事件的独立是同一个分布内的两个子集独立，而每个随机变量都代表了 $V$ 上的一个分布。

关于随机变量，有一个著名的生日悖论：如果我们观察同一个随机变量很多次，大概在 $1.2\times\sqrt{\vert{U}\vert}$ 次的时候我们看到重复元素的概率大于 $\frac12$。

#### 异或

现在我们重点关注这样一个世界 $U=\\{0,1\\}^n$ 其中每一个元素都是由一个 $n$ 比特串构成的。其中有两个独立随机变量 $X,Y$。 $X$ 是任意分布的随机变量，而 $Y$ 是一个均匀分布的随机变量。那么由 $X,Y$ 经过异或运算得到的随机变量 $Z=X \oplus Y$ 是一个均匀分布的随机变量。异或的这个独特性质让他成为密码学中非常重要的工具。（密码学本质就是各种东西异或到一起XD）

证明的方式也非常简单。我们来计算 $Z$ 是任何一个元素的概率 $P(Z=z)$ 。对于 $U$ 中任何一个 $X=x$ 我们都可以找到一个 $Y=y$ 让 $x \oplus y_x = z$ 。而 $X,Y$ 独立，我们可以得出

$$p(Z=z) = \sum_{x \in V} p(X=x)p(Y=y_x)$$

因为 $Y$ 是一个均匀分布，所以 $p(Y=y_x) = \frac{1}{\vert{U}\vert}$ 提取公因子得出

$$p(Z=z) = \frac{1}{\vert U\vert}\sum_{x \in V} p(X=x)$$

后一项就是 $V$ 中所有元素概率之和为1，所以得出 $Z$ 是一个均匀随机变量

$$p(Z=z) = \frac{1}{\vert U\vert}$$
